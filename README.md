# AI Code Quality Reviewer (LangGraph + LlamaIndex + HITL)

## ğŸ“Œ Overview

This project is an **AI-powered code quality reviewer** designed to analyze Java repositories.

It evaluates the overall **code quality and risk level** and classifies it into:

* **LOW** â€“ Code is acceptable and production-ready
* **MEDIUM** â€“ Code needs refactoring or improvements
* **HIGH** â€“ Major design, security, or architectural issues detected

The system is **deterministic, explainable, and human-aware**, making it suitable for real-world engineering teams.

---

## ğŸ§  Why This Project Exists

Traditional AI code reviewers:

* Often behave like black boxes
* Lack workflow control
* Do not understand *why* a developer wrote code a certain way

This project solves that by combining:

* **LangGraph** â†’ Workflow orchestration & decision enforcement
* **LlamaIndex** â†’ Semantic code context retrieval
* **LLMs** â†’ Code reasoning and classification
* **Human-in-the-Loop (HITL)** â†’ Developer intent & justification

---

## ğŸ—ï¸ High-Level Architecture

```
GitHub Repo
    â†“
Fetch Java Files (GitHub API)
    â†“
LlamaIndex (Semantic Context Retrieval)
    â†“
LLM Code Analysis
    â†“
Risk Classification (LOW / MEDIUM / HIGH)
    â†“
[If MEDIUM or HIGH]
    â†’ Human-in-the-Loop (Developer Intent)
    â†’ Re-analysis with Intent
    â†’ Final Classification
```

---

## ğŸ§© Core Concepts

### 1ï¸âƒ£ LangGraph (Workflow Orchestrator)

* Controls **states, transitions, and decisions**
* Ensures:

  * HITL is triggered only when required
  * Workflow is deterministic
  * Results are auditable

### 2ï¸âƒ£ LlamaIndex (Context Engine)

* Understands relationships across files
* Retrieves relevant code sections
* Prevents shallow file-by-file analysis

### 3ï¸âƒ£ Human-in-the-Loop (HITL)

* Activated only for **MEDIUM or HIGH risk**
* Allows developers to explain:

  * Design trade-offs
  * Performance constraints
  * Business-driven decisions
* Re-analysis respects justified intent

---

## ğŸ“ Project Structure

```
ai-code-reviewer/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                     # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ state.py                # LangGraph state definition
â”‚   â”‚   â””â”€â”€ workflow.py             # Workflow orchestration
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ fetch_github_code.py    # Fetch Java files from GitHub
â”‚   â”‚   â”œâ”€â”€ retrieve_context.py     # LlamaIndex context retrieval
â”‚   â”‚   â”œâ”€â”€ analyze_code.py         # LLM analysis (intent-aware)
â”‚   â”‚   â”œâ”€â”€ classify_risk.py        # LOW / MEDIUM / HIGH classification
â”‚   â”‚   â””â”€â”€ human_loop.py           # Human-in-the-loop node
â”‚   â”‚
â”‚   â”œâ”€â”€ github/
â”‚   â”‚   â””â”€â”€ github_client.py        # GitHub API wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ analysis_prompt.txt
â”‚   â”‚   â”œâ”€â”€ classification_prompt.txt
â”‚   â”‚   â””â”€â”€ hitl_prompt.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ llm_provider.py         # LLM initialization
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ parser.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš™ï¸ Prerequisites

* Python **3.10+**
* GitHub account (public or private repo)
* OpenAI API key (or replaceable with Ollama later)

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/<your-username>/ai-code-reviewer.git
cd ai-code-reviewer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ” Environment Configuration

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your-openai-key

GITHUB_OWNER=your-github-username
GITHUB_REPO=your-repo-name
GITHUB_BRANCH=main
GITHUB_TOKEN=ghp_xxxxxx   # Optional (required for private repos)
```

---

## â–¶ï¸ How to Run

```bash
python app/main.py
```

### Possible Outcomes

* **LOW** â†’ Process ends automatically
* **MEDIUM / HIGH** â†’ You will be prompted to explain your design intent

Example:

```
âš ï¸ HUMAN REVIEW REQUIRED âš ï¸
Current Risk: MEDIUM

Explain WHY this design was chosen:
> Inventory updates are async to avoid order latency under peak load
```

The system will re-analyze and produce a **final verdict**.

---

## ğŸ“Š Output Example

```
FINAL RESULT
Risk Level: MEDIUM
```

---

## ğŸ§ª Supported Use Cases

* Direct pushes without PR/MR
* Monorepos with deep folder structures
* Microservice architectures
* Orderâ€“Inventory / Saga patterns

---

## ğŸ§  Design Principles

* **Deterministic workflows over autonomous agents**
* **Human-in-the-loop only when necessary**
* **Separation of concerns** (flow vs context vs reasoning)
* **Auditability & explainability**

---

## ğŸ§‘â€ğŸ’» Maintainer Notes

This project is intentionally designed to be:

* Interview-presentable
* Production-extendable
* Architecture-focused

> **LangGraph enforces policy, LlamaIndex provides context, LLMs reason, and humans provide intent.**

---
<img width="1335" height="772" alt="architecture-diagram" src="https://github.com/user-attachments/assets/e4cb4bf6-aaaa-48b8-8729-5e63bbd5bd06" />

